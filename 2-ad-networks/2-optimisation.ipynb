{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center> Crash Course on Variational Monte Carlo </center>\n",
    "<center> Lecture 3: AD and Neural Networks</center>\n",
    "\n",
    "<h3><center>Filippo Vicentini</center></h3>\n",
    "\n",
    "<center>filippo.vicentini@epfl.ch</center>\n",
    "\n",
    "\n",
    "<center>https://github.com/PhilipVinc/vmc-crash-course-2010</center>\n",
    "\n",
    "\n",
    "\n",
    "EPFL, 22 October 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# Some imports®\n",
    "import jax\n",
    "import numpy as np\n",
    "from jax import numpy as jnp\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# <center>Jastrow Wavefunction</center>\n",
    "\n",
    "The jastrow ansatz for the wavefunction is:\n",
    "$$\n",
    "\\psi_{W}(\\sigma_1, \\dots, \\sigma_N) = \\exp[\\sum_{i,j} \\sigma_i W_{i,j} \\sigma_j] = \\exp[\\sigma^T W \\sigma]\n",
    "$$\n",
    "\n",
    "We actually want to encode the \n",
    "$$\n",
    "\\log\\psi_{W}(\\sigma_1, \\dots, \\sigma_N) = \\sigma^T W \\sigma\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using NetKet \n",
    "The devil is still in the python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Importing netket (that ain't too hard)\n",
    "import netket as nk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# How many spins we want in our model\n",
    "N = 8 \n",
    "\n",
    "# Define a 1D lattice (or graph) for our model\n",
    "graph = nk.graph.Grid([N], pbc=True)\n",
    "\n",
    "# Define the Hilbert space\n",
    "ℋ = nk.hilbert.Spin(graph, s=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Ĥ = nk.operator.Ising(h=2.0, hilbert=ℋ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Defining Neural Networks in Jax\n",
    "\n",
    "A simple example: The RBM (Restricted Boltzmann Machine):\n",
    "$$\n",
    " \\psi(\\sigma) = \\sum_{j=1}^{\\alpha N} \\mathcal{G}\\left(\\sum_{i=1}^N W_i^j \\sigma_j + b_i\\right)\n",
    "$$\n",
    "But i prefer to write it like:\n",
    "$$\n",
    "    \\psi(\\sigma) = \\left[\\Sigma \\circ \\mathcal{G} \\circ D\\right] (\\sigma)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The dense layer (also known as affine layer)\n",
    "The dense layer is an affine transformation:\n",
    "$$\n",
    " \\vec{D} (\\sigma) = W \\vec\\sigma +  \\vec{b}   \n",
    "$$\n",
    "\n",
    "note: Sometimes, the element-wise activation function is included in the dense layer (but we do not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Stax is an (experimental) submodule with neural-network related stuff\n",
    "from jax.experimental import stax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "α = 2 # We define the hidden layer density\n",
    "dense = stax.Dense(α * ℋ.size) # As we have shown last time, this is actually a tuple of functions...\n",
    "dense_init, dense_apply = dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dense layer output shape is: (-1, 16)\n",
      "The dense layer weights has type: <class 'tuple'> of length  2\n",
      "\t dense_weights[0] =  <class 'jax.interpreters.xla.DeviceArray'> , shape = (8, 16) , dtype= float32\n",
      "\t dense_weights[1] =  <class 'jax.interpreters.xla.DeviceArray'> , shape = (16,)   , dtype= float32\n"
     ]
    }
   ],
   "source": [
    "dense_out_shape, dense_weights = dense_init(jax.random.PRNGKey(0), (-1, ℋ.size))\n",
    "print(\"The dense layer output shape is:\", dense_out_shape)\n",
    "print(\"The dense layer weights has type:\", type(dense_weights), \"of length \", len(dense_weights))\n",
    "print(\"\\t dense_weights[0] = \", type(dense_weights[0]), \", shape =\", dense_weights[0].shape, \", dtype=\", dense_weights[0].dtype)\n",
    "print(\"\\t dense_weights[1] = \", type(dense_weights[1]), \", shape =\", dense_weights[1].shape, \"  , dtype=\", dense_weights[1].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The activation function\n",
    "We chose logcosh: \n",
    "\n",
    "$$ \n",
    "    \\mathcal{G}\\circ \\vec{x} = log\\circ cosh \\circ \\vec{x} \n",
    "$$\n",
    "    \n",
    "This is always applied elementwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# We define our activation function\n",
    "def logcosh(x):\n",
    "    # log(cosh(x)) but smarter\n",
    "    x = x * jnp.sign(x.real)\n",
    "    return x + jnp.log(1.0 + jnp.exp(-2.0 * x)) - jnp.log(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# We define the layer applying the activation function element-wise\n",
    "LogCoshLayer = stax.elementwise(logcosh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The elementwise layer output shape is: (-1, 16)\n",
      "The elementwise layer weights has type: <class 'tuple'> of length  0\n"
     ]
    }
   ],
   "source": [
    "ew_shape, ew_weights = LogCoshLayer[0](jax.random.PRNGKey(0), dense_out_shape)\n",
    "print(\"The elementwise layer output shape is:\", ew_shape)\n",
    "print(\"The elementwise layer weights has type:\", type(ew_weights), \"of length \", len(ew_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The reduction layer\n",
    "We take as reduction the sum of all the inputs $x\\in\\mathbb{R}^M$:\n",
    "\n",
    "$$\n",
    "\\Sigma \\circ \\vec{x} = \\sum_i^{M} x_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# The reduction layer\n",
    "def SumLayer():\n",
    "    def init_fun(rng, input_shape):\n",
    "        output_shape = (-1, 1)\n",
    "        return output_shape, ()\n",
    "\n",
    "    def apply_fun(params, inputs, **kwargs):\n",
    "        return inputs.sum(axis=-1)\n",
    "\n",
    "    return init_fun, apply_fun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Chaining the functions together\n",
    "$$\n",
    "    \\psi = \\left[\\Sigma \\circ \\mathcal{G} \\circ D\\right]\n",
    "$$\n",
    "\n",
    "Known as a serial layer or chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#And we can put everything together by chaining everything with a serial (or chain) object:\n",
    "neural_net = stax.serial(stax.Dense(α * ℋ.size), stax.elementwise(logcosh), SumLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Wrap it in a netket machine object, associating the hilbert space\n",
    "ψ = nk.machine.Jax(ℋ, neural_net, dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Intermezzo: About PyTrees\n",
    "Jax, PyTorch, Flux, and basically ANY modern ML framework store parameters in a ~~Py~~Tree.\n",
    "\n",
    "A ~~Py~~Tree tree structure of containers, ordered or unordered, recursively nested, which might or might not hold some leaf nodes. \n",
    "Data is only stored in leaf nodes, which are usually N-d arrays or similar structures holding state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ψ has  3 sets of parameters, 1 per layer:\n",
      "\t 1. has length: 2 with shapes: (8, 16) and  (16,)\n",
      "\t 2. has length: 0\n",
      "\t 3. has length: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"ψ has \", len(ψ.parameters), \"sets of parameters, 1 per layer:\")\n",
    "print(\"\\t 1. has length:\", len(ψ.parameters[0]), \"with shapes:\", \n",
    "          ψ.parameters[0][0].shape, \"and \", ψ.parameters[0][1].shape)\n",
    "print(\"\\t 2. has length:\", len(ψ.parameters[1]))\n",
    "print(\"\\t 3. has length:\", len(ψ.parameters[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Transformations you can do on trees:\n",
    "\n",
    "  - Apply a function to all leaf nodes, return the transformed tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 16)\n",
      "(16,)\n"
     ]
    }
   ],
   "source": [
    "jax.tree_map(lambda x: print(x.shape),  ψ.parameters);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  - Flatten the tree into an ordered list of leaf-nodes, and additional data used to reconstruct the tree from the flattened data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_pars has is a <class 'list'> with 2 leaf-nodes inside:\n",
      "\t the 0 - th element is a <class 'jax.interpreters.xla.DeviceArray'> of dtype float32 and shape (8, 16)\n",
      "\t the 1 - th element is a <class 'jax.interpreters.xla.DeviceArray'> of dtype float32 and shape (16,)\n",
      "tree_structure is a: <class 'jaxlib.xla_extension.PyTreeDef'>\n"
     ]
    }
   ],
   "source": [
    "flat_pars, tree_structure = jax.tree_flatten(ψ.parameters)\n",
    "print(\"flat_pars has is a\", type(flat_pars), \"with\", len(flat_pars), \"leaf-nodes inside:\")\n",
    "for (i, el) in enumerate(flat_pars):\n",
    "    print(\"\\t the\", i,\"- th element is a\", type(el), \"of dtype\", el.dtype, \"and shape\", el.shape)\n",
    "print(\"tree_structure is a:\", type(tree_structure))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "  - Reconstruct the PyTree from the flattened data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_tree has  3 sets of parameters:\n",
      "\t 1. has length: 2 with shapes: (8, 16) and  (16,)\n",
      "\t 2. has length: 0\n",
      "\t 3. has length: 0\n"
     ]
    }
   ],
   "source": [
    "new_tree = jax.tree_unflatten(tree_structure, flat_pars)\n",
    "print(\"new_tree has \", len(new_tree), \"sets of parameters:\")\n",
    "print(\"\\t 1. has length:\", len(ψ.parameters[0]), \"with shapes:\", \n",
    "          ψ.parameters[0][0].shape, \"and \", ψ.parameters[0][1].shape)\n",
    "print(\"\\t 2. has length:\", len(ψ.parameters[1]))\n",
    "print(\"\\t 3. has length:\", len(ψ.parameters[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Back To all our ingredients to optimise the energy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# The machine:\n",
    "ψ = nk.machine.Jax(ℋ, neural_net, dtype=float)\n",
    "\n",
    "# Local sampler (we saw it the previous lecture)\n",
    "sampler = nk.sampler.MetropolisLocal(ψ, n_chains=16, sweep_size=N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def sample(sampler, n_samples):\n",
    "    sampler.reset()\n",
    "    sampler.generate_samples(n_samples//10)\n",
    "    σs = sampler.generate_samples(n_samples)\n",
    "    return σs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from netket.operator import local_values\n",
    "def estimate_observable(Ô, ψ, σ_samples):\n",
    "    \n",
    "    # Flatten the batch and chain dimensions\n",
    "    N = σ_samples.shape[-1]\n",
    "    σ_samples_r = σ_samples.reshape((-1, N))\n",
    "\n",
    "    # Compute the  Oᴸᵒᶜ(σ)\n",
    "    loc = local_values(Ô, ψ, σ_samples_r).reshape(σ_samples.shape[0:2])\n",
    "    \n",
    "    return loc, nk.stats.statistics(loc.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<H> =  -11.966+0.000j ± 0.039 [σ²=12.126, R̂=1.0001]\n"
     ]
    }
   ],
   "source": [
    "σs = sample(sampler, 500)\n",
    "elocs, stat = estimate_observable(Ĥ, ψ, σs)\n",
    "print(\"<H> = \", stat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### The gradient of the local energy\n",
    "Recall:\n",
    "$$\n",
    "    F_k = \\langle \\hat{E}^\\text{Loc} \\hat{O}_k \\rangle -  \\langle\\hat{E}^\\text{Loc}\\rangle \\langle\\hat{O}_k \\rangle = \\langle \\Delta\\hat{E}^\\text{Loc} \\Delta\\hat{O}_k \\rangle\n",
    "$$\n",
    "\n",
    "where \n",
    "$$\n",
    "\\Delta\\hat{O} =\\Delta\\hat{O} - \\langle \\Delta\\hat{O} \\rangle \n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def estimate_gradient(σ_samples, ψ, Eloc):\n",
    "    # Center the Local energies: Eᴸᵒᶜ = Eᴸᵒᶜ - ⟨Eᴸᵒᶜ⟩ \n",
    "    Eloc -= nk.stats.mean(Eloc)\n",
    "    \n",
    "    # Flatten the batch dimension\n",
    "    N = σ_samples.shape[-1]\n",
    "    σ_samples_r = σ_samples.reshape((-1, N))\n",
    "    n_samples_tot = σ_samples_r.shape[0]\n",
    "    Eloc_r = Eloc.reshape(-1, 1)\n",
    "    \n",
    "    # Compute the propagation of the \n",
    "    grads = ψ.vector_jacobian_prod(σ_samples_r, Eloc_r / n_samples_tot)\n",
    "\n",
    "    # if real parameters but complex gradient, take only real part\n",
    "    if not ψ.has_complex_parameters:\n",
    "        return nk.vmc_common.tree_map(lambda x: x.real, grads)\n",
    "    else:\n",
    "        return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Iterative optimisation according to gradient descent.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# So to perform one step of optimisation...\n",
    "n_samples = 2000\n",
    "F = estimate_gradient(σs, ψ, elocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Build the optimiser\n",
    "op = nk.optimizer.jax.Sgd(ψ, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Generate the new parameters\n",
    "new_params = op.update(F, ψ.parameters)\n",
    "\n",
    "# Replace the old parameters with the new\n",
    "ψ.parameters = new_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "## This cell is here so that I don't have to go back up if I try to change the network...\n",
    "\n",
    "N = 8\n",
    "\n",
    "# Define a 1D lattice (or graph) for our model\n",
    "graph = nk.graph.Grid([N], pbc=True)\n",
    "\n",
    "# Define the Hilbert space\n",
    "ℋ = nk.hilbert.Spin(graph, s=0.5)\n",
    "\n",
    "neural_net = stax.serial(stax.Dense(2 * ℋ.size), stax.elementwise(logcosh), SumLayer())\n",
    "\n",
    "ψ = nk.machine.Jax(ℋ, neural_net, dtype=float)\n",
    "\n",
    "# Local sampler (we saw it the previous lecture)\n",
    "sampler = nk.sampler.MetropolisLocal(ψ, n_chains=16, sweep_size=N)\n",
    "\n",
    "# The ham\n",
    "Ĥ = nk.operator.Ising(h=0.6, hilbert=ℋ)\n",
    "\n",
    "op = nk.optimizer.jax.Sgd(ψ, learning_rate=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "Evals = []\n",
    "for i in range(100):\n",
    "    σs = sample(sampler, 500)\n",
    "    elocs, stat = estimate_observable(Ĥ, ψ, σs)\n",
    "    \n",
    "    F = estimate_gradient(σs, ψ, elocs)\n",
    "    ψ.parameters = op.update(F, ψ.parameters)\n",
    "    \n",
    "    Evals.append(stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Exact solution\n",
    "sol = nk.exact.lanczos_ed(Ĥ)\n",
    "E0 = sol.eigenvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x1441240a0>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([e.mean for e in Evals])\n",
    "#plt.plot([e.mean for e in Evals2])\n",
    "plt.hlines([E0], xmin=0, xmax=len(Evals), colors=['red'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Teaching-1-netket",
   "language": "python",
   "name": "teaching-1-netket"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
